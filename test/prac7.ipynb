{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Реализовать классы нейросетей по аналогии с классом OurNeuralNetwork."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    # Функция активации: f(x) = 1/(1+e^(-x))\n",
    "    return 1/(1+np.exp(-x))\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "weights = np.array([0,1])    # w1 = 0, w2 = 1\n",
    "bias = 4    # c = 4\n",
    "n = Neuron(weights, bias)\n",
    "x = np.array([2,3])   # x = 2, y = 3\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, x, y):\n",
    "        self.input    = x\n",
    "        self.weights1 = np.random.rand(self.input.shape[1],4)\n",
    "        self.weights2 = np.random.rand(4,1)\n",
    "        self.y        = y\n",
    "        self.output   = np.zeros(y.shape)\n",
    "    def feedforward(self):\n",
    "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
    "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
    "class OurNeuralNetwork:\n",
    "    \"\"\"\n",
    "    данные нейросети:\n",
    "        − три входа (𝑥1,𝑥2,𝑥3);\n",
    "        − три нейрона в скрытых слоях (ℎ1,ℎ2,ℎ3);\n",
    "        − выход (𝑜1).\n",
    "    нейроны имеют идентичные веса и пороги:\n",
    "        − 𝑤 = [0.5,0.5,0.5]\n",
    "        − 𝑏 = 0\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5,0.5,0.5])\n",
    "        bias = 0\n",
    "        # класс Neuron из предыдущего раздела\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.h3 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        # входы для о1 - это выходы h1 и h2 и h3\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2,3,4])\n",
    "print(network.feedforward(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8671195555587996\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class OurNeuralNetwork:\n",
    "    \"\"\"\n",
    "    данные нейросети:\n",
    "        - два входа\n",
    "        - два нейрона в скрытых слоях (h1, h2)\n",
    "        - выход (о1, o2)\n",
    "    нейроны имеют идентичные веса и пороги:\n",
    "        - w = [1,0]\n",
    "        - b = 1\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        weights = np.array([1,0])\n",
    "        bias = 1\n",
    "        # класс Neuron из предыдущего раздела\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "        self.o2 = Neuron(weights, bias)\n",
    "        self.o = Neuron(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        # входы для о1 - это выходы h1 и h2\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h2, out_h1]))\n",
    "        out_o = self.o.feedforward(np.array([out_o2, out_o1]))\n",
    "        return out_o\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2,3])\n",
    "print(network.feedforward(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализуйте классы нейронных сетей с использованием других функций активации.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MLPClassifier\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Sizes:  (1797, 64) (1797,)\n",
      "Dataset Sizes:  (506, 13) (506,)\n",
      "Train/Test sizes:  (1437, 64) (360, 64) (1437,) (360,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sad/PycharmProjects/pythonProject2/venv/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "libtk8.6.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [5], line 45\u001B[0m\n\u001B[1;32m     20\u001B[0m MLPClassifier(\n\u001B[1;32m     21\u001B[0m     activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrelu\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     22\u001B[0m     alpha\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0001\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m     warm_start\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     43\u001B[0m )\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pyplot \u001B[38;5;28;01mas\u001B[39;00m plt\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mturtle\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m color\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m confusion_matrix\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_confusion_matrix\u001B[39m(Y_test, Y_preds):\n",
      "File \u001B[0;32m/usr/lib/python3.10/turtle.py:107\u001B[0m\n\u001B[1;32m    103\u001B[0m _ver \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mturtle 1.1b- - for Python 3.1   -  4. 5. 2009\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;66;03m# print(_ver)\u001B[39;00m\n\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtkinter\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mTK\u001B[39;00m\n\u001B[1;32m    108\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtypes\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/tkinter/__init__.py:37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtypes\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01m_tkinter\u001B[39;00m \u001B[38;5;66;03m# If this fails your Python may not be configured for Tk\u001B[39;00m\n\u001B[1;32m     38\u001B[0m TclError \u001B[38;5;241m=\u001B[39m _tkinter\u001B[38;5;241m.\u001B[39mTclError\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtkinter\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n",
      "\u001B[0;31mImportError\u001B[0m: libtk8.6.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits, load_boston\n",
    "\n",
    "digits = load_digits()\n",
    "X_digits, Y_digits = digits.data, digits.target\n",
    "print('Dataset Sizes: ', X_digits.shape, Y_digits.shape)\n",
    "from sklearn.datasets import load_digits, load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "X_boston, Y_boston = boston.data, boston.target\n",
    "print('Dataset Sizes: ', X_boston.shape, Y_boston.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(random_state=123)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_digits, Y_digits,\n",
    "                                     train_size=0.80, test_size=0.20, stratify=Y_digits, random_state=123)\n",
    "\n",
    "print('Train/Test sizes: ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "mlp_classifier.fit(X_train, Y_train)\n",
    "MLPClassifier(\n",
    "    activation='relu',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    early_stopping=False,\n",
    "    epsilon=1e-08,\n",
    "    hidden_layer_sizes=(100,),\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=200,\n",
    "    momentum=0.9,\n",
    "    n_iter_no_change=10,\n",
    "    nesterovs_momentum=True,\n",
    "    power_t=0.5,\n",
    "    random_state=123,\n",
    "    shuffle=True,\n",
    "    solver='adam',\n",
    "    tol=0.0001,\n",
    "    validation_fraction=0.1,\n",
    "    verbose=False,\n",
    "    warm_start=False\n",
    ")\n",
    "from matplotlib import pyplot as plt\n",
    "from turtle import color\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(Y_test, Y_preds):\n",
    "    conf_mat = confusion_matrix(Y_test, Y_preds)\n",
    "    #print(conf_mat)\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    plt.matshow(conf_mat, cmap=plt.cm.Blues, fignum=1)\n",
    "    plt.yticks(range(10), range(10))\n",
    "    plt.xticks(range(10), range(10))\n",
    "    plt.colorbar();\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            plt.text(i-0.2,j+0.1, str(conf_mat[j,i]), color='tab:red')\n",
    "plot_confusion_matrix(Y_test, mlp_classifier.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Задание\n",
    "\n",
    "Задача: Используйте классы MLPClassified и MLPRegressor для классификации и регрессии произвольных данных из интернета. Проведите анализ атрибуты, полученных моделей. Для классификации можете взять набор данных Ирисов: https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv а для регрессии датасет зависимости заработной платы от опыта работы: https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sad/PycharmProjects/pythonProject2/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_3554/3458819431.py:22: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(y_test[:15])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Setosa' 'Setosa' 'Virginica' 'Versicolor' 'Virginica' 'Versicolor'\n",
      " 'Setosa' 'Setosa' 'Setosa' 'Setosa' 'Setosa' 'Virginica' 'Versicolor'\n",
      " 'Versicolor' 'Versicolor']\n",
      "19         Setosa\n",
      "49         Setosa\n",
      "83     Versicolor\n",
      "93     Versicolor\n",
      "113     Virginica\n",
      "69     Versicolor\n",
      "31         Setosa\n",
      "37         Setosa\n",
      "25         Setosa\n",
      "10         Setosa\n",
      "39         Setosa\n",
      "107     Virginica\n",
      "51     Versicolor\n",
      "94     Versicolor\n",
      "50     Versicolor\n",
      "Name: variety, dtype: object\n",
      "Test Accurancy: 0.933\n",
      "Training Accurancy: 0.975\n",
      "Loss:  0.32402012120284457\n",
      "Number of coefs:  2\n",
      "Number of intercepts:  2\n",
      "Number of iterations for which estimator ran:  200\n",
      "Name of output layer activation function:  softmax\n",
      "(24, 1) (6, 1) (24,) (6,)\n",
      "[20.26234628 55.2781752  18.82135812 50.48274487 20.26234628 50.9622879 ]\n",
      "[ 54445. 121872.  56642. 116969.  64445. 112635.]\n",
      "Test R^2: -8.796\n",
      "Training R^2: -8.261\n",
      "Loss:  2988058032.1601596\n",
      "Number of coefs:  2\n",
      "Number of intercepts:  2\n",
      "Number of iterations for which estimator ran:  200\n",
      "Name of output layer activation function:  identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sad/PycharmProjects/pythonProject2/venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "url = r'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:,:-1],    # все колонки кроме последней - в признаки\n",
    "    data.iloc[:,-1], # последнюю в целевую переменную (класс)\n",
    "    test_size = 0.20 # размер тестовой выборки 20%\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(random_state=123)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "\n",
    "print(Y_preds[:15])\n",
    "print(y_test[:15])\n",
    "## ммтедо Score для оценки точности моделей классификации\n",
    "print('Test Accurancy: %.3f'%mlp_classifier.score(X_test, y_test))\n",
    "print('Training Accurancy: %.3f'%mlp_classifier.score(X_train, y_train))\n",
    "print(\"Loss: \", mlp_classifier.loss_)\n",
    "print(\"Number of coefs: \", len(mlp_classifier.coefs_))\n",
    "print(\"Number of intercepts: \", len(mlp_classifier.intercepts_))\n",
    "print(\"Number of iterations for which estimator ran: \", mlp_classifier.n_iter_)\n",
    "print(\"Name of output layer activation function: \", mlp_classifier.out_activation_)\n",
    "url = r'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.iloc[:,:-1].values,    # все колонки кроме последней - в признаки\n",
    "    data.iloc[:,-1].values, # последнюю в целевую переменную (класс)\n",
    "    test_size = 0.20, # размер тестовой выборки 20%\n",
    "    random_state=123\n",
    ")\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp_regressor = MLPRegressor(random_state=123)\n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "print(Y_preds[:10])\n",
    "print(y_test[:10])\n",
    "## ммтедо Score для оценки точности моделей классификации\n",
    "print('Test R^2: %.3f'%mlp_regressor.score(X_test, y_test))\n",
    "print('Training R^2: %.3f'%mlp_regressor.score(X_train, y_train))\n",
    "print(\"Loss: \", mlp_regressor.loss_)\n",
    "print(\"Number of coefs: \", len(mlp_regressor.coefs_))\n",
    "print(\"Number of intercepts: \", len(mlp_regressor.intercepts_))\n",
    "print(\"Number of iterations for which estimator ran: \", mlp_regressor.n_iter_)\n",
    "print(\"Name of output layer activation function: \", mlp_regressor.out_activation_)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
